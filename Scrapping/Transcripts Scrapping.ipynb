{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "###### Observing the pattern of the order of webpage gave a idea of progession of web page which is used in this program to call the web page in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstr = 'https://vedabase.io'\n",
    "Transdict= defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,308):\n",
    "        print(i)\n",
    "        r = requests.get(r'https://vedabase.io/en/library/transcripts/?page='+str(i))\n",
    "        #requesting full webpage\n",
    "        main= soup(r.text,'lxml')\n",
    "        trans_list =main.find_all('div', class_ ='col-12 r')\n",
    "        rand_var = r'/en/library/transcripts/.*?/'\n",
    "        #making a variable that updates itself to search for pages one by one\n",
    "        print(rand_var)\n",
    "        for j in range (1,12):\n",
    "            list1=[]\n",
    "            x1=re.search(rand_var,str(trans_list))\n",
    "            p2=str(x1.group())\n",
    "            trans_list = re.sub(p2,'',str(trans_list),1)\n",
    "            url3= mstr + p2\n",
    "            print(url3)\n",
    "            \n",
    "            \n",
    "            m=[]\n",
    "            l = requests.get(url3)\n",
    "            main= soup(l.text,'lxml')\n",
    "            d=str(main.find_all('div',class_=\"rich-text\"))\n",
    "\n",
    "            while(re.search('<.+?>',d)):\n",
    "                d = re.sub('<.+?>','',d,1)\n",
    "                #removing all tags\n",
    "                \n",
    "#searching for paaterns\n",
    "            patternsList=[None for i in range(3)]\n",
    "            pat5=re.findall('\\[BG.*?\\]',d)\n",
    "            pat6=re.findall('\\[Bg.*?\\]',d)\n",
    "            pat7=re.findall('\\[SB.*?\\]',d)\n",
    "            patternList=[pat5+pat6+pat7]\n",
    "            print(patternList)\n",
    "            Transdict[p2].append(patternList)\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(Transdict,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('TransScript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Complex pattern not used \n",
    "pat1=re.findall('Bhāgavatam [(]\\d.*[)]',d)\n",
    "pat2=re.findall('Bhagavad-gītā [(]\\d.*?[)]',d)\n",
    "pat3=re.findall('Gītā [(]\\d.*[)]',d)\n",
    "pat4=re.findall('[(]\\D.*?[)]',d)\n",
    "pat5=re.findall('..................[(]\\d.*?[)]',d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
